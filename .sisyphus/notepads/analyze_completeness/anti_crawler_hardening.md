# Anti-Crawler Hardening Implemented

## 🛡️ 已实施的防护措施

### 1. 智能延迟升级 (SmartDelayController)
- **基础延迟**: 从 `3.0s` 提升至 `5.0s`。
- **随机抖动**: 从 `±20%` 增加到 `±40%`，使请求间隔更像人类。
- **高峰期避让**: 
  - 晚高峰 (19-23点): 延迟 x2.0
  - 工作时间 (9-18点): 延迟 x1.5
- **强制休息**: 每 50 次请求（原100次）随机休息 30-60 秒。

### 2. Cookie 健康检查 (Check Cookie)
- **启动前检查**: 每次运行前自动访问 `get_homefeed_all_channel`。
- **失效熔断**: 如果 Cookie 失效，程序直接报错停止，避免无效请求触发风控。

### 3. 会话预热 (Warm-up)
- **模拟浏览**: 启动爬虫前，先随机浏览首页推荐流和 1-2 篇笔记。
- **建立信任**: 让账号看起来像是在"逛"而不是上来就"搜"。

### 4. 浏览器指纹优化 (User-Agent Rotation)
- **随机 UA**: 从预设的 User-Agent 池中随机选择一个（包含 Chrome/Safari/Edge）。
- **动态 Header**: 在搜索请求中覆盖默认的 User-Agent，减少特征识别。

## 💡 给用户的建议

1. **更换 Cookie 后**：
   - 请先在浏览器手动浏览几分钟。
   - 更新 `.env`。
   - 运行 `python run.py --spider --mode city`。

2. **长期运行**：
   - 建议使用 `python run.py --auto-schedule`。
   - 自动化脚本会在凌晨（非高峰期）运行，且每天只有一次，是最安全的策略。

3. **如果再次被封**：
   - 休息 24 小时通常会自动解封。
   - 考虑配置 `PROXIES` 使用代理 IP（代码已支持，只需在 `.env` 配置）。
