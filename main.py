# -*- coding: utf-8 -*-
"""
DrissionPage å°çº¢ä¹¦æ‰¹é‡çˆ¬è™« 
æ ¸å¿ƒç­–ç•¥ï¼šç§»é™¤æ‰€æœ‰ API ç›‘å¬ (é™ä½ç‰¹å¾) -> çº¯ DOM äº¤äº’ (ç‚¹å‡»/æ»šåŠ¨) -> è¢«åŠ¨ SSR/DOM æå–
æ”¯æŒå­˜å‚¨æ ¼å¼ï¼šCSVã€JSONã€Excelã€SQLite
"""
import sys
import argparse
from loguru import logger
from xhs_utils.xhs_spider import DrissionXHSSpider

# é…ç½®æ—¥å¿—è‡ªåŠ¨ä¿å­˜
logger.add("logs/spider_{time:YYYY-MM-DD}.log", rotation="1 day", retention="7 days", encoding="utf-8")

def main():
    parser = argparse.ArgumentParser(description="DrissionPage å°çº¢ä¹¦çˆ¬è™« ")
    parser.add_argument("--keywords", "-k", nargs="+", help="å…³é”®è¯åˆ—è¡¨")
    parser.add_argument("--limit", "-l", type=int, default=20, help="æ¯ä¸ªå…³é”®è¯æœ€å¤šçˆ¬å–æ•°é‡")
    parser.add_argument("--daily-limit", "-d", type=int, default=50,
                        help="æ¯æ—¥æœ€å¤šçˆ¬å–æ€»æ•°ï¼ˆæ¨è 50-100ï¼‰")
    parser.add_argument("--min-likes", type=int, default=0,
                        help="æœ€å°‘ç‚¹èµæ•°è¿‡æ»¤ï¼ˆè·³è¿‡ä½äº’åŠ¨ç¬”è®°ï¼Œå‡å°‘è¯·æ±‚ï¼‰")
    parser.add_argument("--storage", "-s", type=str, default="sqlite",
                        choices=["csv", "json", "excel", "sqlite"],
                        help="å­˜å‚¨æ ¼å¼ (csv/json/excel/sqliteï¼Œé»˜è®¤: sqlite)")
    parser.add_argument("--output", "-o", type=str, default="datas",
                        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: datasï¼‰")
    parser.add_argument("--no-warmup", action="store_true", help="è·³è¿‡ä¼šè¯é¢„çƒ­")
    parser.add_argument("--no-shuffle", action="store_true", help="ä¸æ‰“ä¹±å…³é”®è¯é¡ºåº")
    
    # æ–°å¢å‚æ•°
    parser.add_argument("--ignore-progress", action="store_true", help="å¿½ç•¥å†å²è¿›åº¦ï¼ˆå¼ºåˆ¶é‡æ–°çˆ¬å–ï¼‰")
    parser.add_argument("--no-filter", action="store_true", help="å…³é—­å†…å®¹è´¨é‡è¿‡æ»¤ï¼ˆæ”¶é›†æ‰€æœ‰ç¬”è®°ï¼‰")
    parser.add_argument("--min-quality-score", type=int, default=20, help="æœ€ä½è´¨é‡åˆ†æ•°ï¼ˆé»˜è®¤: 20ï¼Œä½äºæ­¤åˆ†æ•°çš„ç¬”è®°å°†è¢«è·³è¿‡ï¼‰")
    parser.add_argument("--static-comments", action="store_true", help="ä½¿ç”¨é™æ€è¯„è®ºé‡‡é›†æ•°é‡ï¼ˆå…³é—­åŠ¨æ€è°ƒæ•´ï¼‰")
    
    # æµè§ˆå™¨æ§åˆ¶å‚æ•°
    parser.add_argument("--new-browser", action="store_true", help="å¯åŠ¨æ–°æµè§ˆå™¨å®ä¾‹ï¼ˆä¸æ¥ç®¡ç°æœ‰æµè§ˆå™¨ï¼‰")
    parser.add_argument("--headless", action="store_true", help="æ— å¤´æ¨¡å¼è¿è¡Œï¼ˆä»…åœ¨å¯åŠ¨æ–°æµè§ˆå™¨æ—¶æœ‰æ•ˆï¼‰")
    
    args = parser.parse_args()
    
    # Use the imported DrissionXHSSpider class
    spider = DrissionXHSSpider(
        storage_type=args.storage, 
        output_dir=args.output,
        takeover=not args.new_browser,
        headless=args.headless
    )
    keywords = args.keywords if args.keywords else ["æ‚‰å°¼å’–å•¡"]
    
    logger.info(f"ğŸ“¦ å­˜å‚¨æ ¼å¼: {args.storage.upper()}")
    logger.info(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output}")
        
    spider.crawl(
        keywords, limit=args.limit,
        daily_limit=args.daily_limit,
        min_likes=args.min_likes,
        warmup=not args.no_warmup,
        shuffle=not args.no_shuffle
    )

if __name__ == "__main__":
    main()

