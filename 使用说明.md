# 小红书爬虫使用说明

## 📦 支持的存储格式

新版爬虫支持 4 种数据存储格式，您可以根据需求选择：

| 格式 | 特点 | 适用场景 |
|------|------|----------|
| **SQLite** | 关系型数据库，支持高级查询 | 大量数据，需要复杂查询 |
| **CSV** | 表格格式，Excel可直接打开 | 数据分析、导入其他工具 |
| **JSON** | 结构化文本，易于程序读取 | 数据交换、API对接 |
| **Excel** | 多工作表，格式美观 | 报告、展示、简单分析 |

## 🚀 快速开始

### 1. 启动 Chrome（调试模式）
```bash
./start_chrome.sh
```

### 2. 运行爬虫

#### 使用 SQLite（默认）
```bash
python mimic_red_engine.py --keywords "澳洲留学" "悉尼大学" --limit 20
```

#### 使用 CSV
```bash
python mimic_red_engine.py --keywords "澳洲留学" --storage csv --limit 20
```

#### 使用 JSON
```bash
python mimic_red_engine.py --keywords "澳洲留学" --storage json --limit 20
```

#### 使用 Excel
```bash
python mimic_red_engine.py --keywords "澳洲留学" --storage excel --limit 20
```

## 📋 命令行参数

| 参数 | 简写 | 说明 | 默认值 |
|------|------|------|--------|
| `--keywords` | `-k` | 关键词列表（空格分隔） | "澳洲留学" |
| `--storage` | `-s` | 存储格式 (csv/json/excel/sqlite) | sqlite |
| `--output` | `-o` | 输出基础目录 | datas |
| `--limit` | `-l` | 每个关键词爬取数量 | 20 |
| `--daily-limit` | `-d` | 每日总爬取上限 | 0（无限制） |
| `--min-likes` | | 最少点赞数过滤 | 0 |
| `--no-warmup` | | 跳过会话预热 | False |
| `--no-shuffle` | | 不打乱关键词顺序 | False |

## 💡 使用示例

### 示例 1：爬取多个关键词，保存为 CSV
```bash
python mimic_red_engine.py \
  --keywords "悉尼大学" "墨尔本大学" "昆士兰大学" \
  --storage csv \
  --limit 30 \
  --output results
```

### 示例 2：每日限量爬取，保存为 Excel
```bash
python mimic_red_engine.py \
  --keywords "澳洲留学" \
  --storage excel \
  --daily-limit 50 \
  --min-likes 100
```

### 示例 3：从数据库读取关键词，保存为 JSON
```bash自定义输出基础目录
```bash
python mimic_red_engine.py \
  --keywords "澳洲留学" \
  --storage json \
  --output my_data \
  --limit 20
```
输出路径：`my_data/json_datas/notes_xxx.json
## 📁 输出文件说明

### 文件夹结构
根据选择的存储格式，数据会自动存储到对应的专用文件夹：
```
项目根目录/
├── sqlite_datas/     # SQLite 数据库文件
├── csv_datas/        # CSV 格式文件
├── json_datas/       # JSON 格式文件
└── excel_datas/      # Excel 格式文件
```

### SQLite 输出
```
csv_sqlite_datas/
  └── notes.db          # SQLite 数据库文件
```

数据库包含两张表：
- `notes`: 笔记主表
- `comments`: 评论表

### CSV 输出
```
datas/
  ├── notes_20260210_120000.csv      # 笔记数据
  └── comments_20260210_120000.csv   # 评论数据
```

### JSON 输出
```
json_datas/
  └── notes_20260210_120000.json     # 包含笔记和评论的完整数据
```

JSON 文件结构：
```json
{
  "notes": [...],
  "comments": [...],
  "crawl_time": "2026-02-10T12:00:00",
  "total_notes": 100,
  "total_comments": 500
}
```

### Excel 输出
```
excel_datas/
  └── notes_20260210_120000.xlsx     # Excel 工作簿
```

Excel 包含两个工作表：
- `Notes`: 笔记数据
- `Comments`: 评论数据

## 🔧 数据字段说明

### 笔记（Notes）
- `note_id`: 笔记唯一ID
- `url`: 笔记链接
- `title`: 标题
- `desc`: 正文内容
- `note_type`: 笔记类型（normal/video）
- `author_id`: 作者ID
- `author_name`: 作者昵称
- `liked_count`: 点赞数
- `collected_count`: 收藏数
- `comment_count`: 评论数
- `total_interaction`: 总互动量
- `traffic_level`: 流量等级（爆款/优质/普通/低质）
- `tags`: 标签（CSV用|分隔，其他为数组）
- `upload_time`: 发布时间
- `keyword_source`: 来源关键词
- `full_text`: 完整文本（标题+正文+标签）

### 评论（Comments）
- `comment_id`: 评论唯一ID
- `note_id`: 所属笔记ID
- `content`: 评论内容
- `author_name`: 评论者昵称
- `like_count`: 点赞数

## ⚠️ 注意事项

1. **Excel 格式需要额外安装依赖**：
   ```bash
   pip install pandas openpyxl
   ```

2. **CSV 文件使用 UTF-8-BOM 编码**，Excel 可直接打开不会乱码

3. **JSON 和 Excel 格式**会在爬取结束时一次性写入文件

4. **SQLite 和 CSV 格式**实时写入，支持断点续爬

5. **数据去重**：所有格式都支持去重，避免重复爬取

## 🔄 数据转换

如果需要在不同格式间转换，可以使用以下工具：

### SQLite → CSV
```bashsqlite_
sqlite3 -header -csv datas/notes.db "SELECT * FROM notes;" > notes.csv
```

### CSV → Excel（使用 Python）
```python
import pandas as pd
df = pd.read_csv('notes.csv')
df.to_excel('notes.xlsx', index=False)
```

### JSON → CSV（使用 Python）
```python
import pandas as pd
data = pd.read_json('notes.json')
data['notes'].to_csv('notes.csv', index=False)
```

## 📚 备份说明

- 旧版 RAG 相关代码已备份到 `backup_rag/` 目录
- 该目录不会上传到 GitHub（已加入 `.gitignore`）
- 如需使用 RAG 功能，请查看备份目录中的代码

## 🆘 常见问题

**Q: Excel 格式报错找不到 pandas？**
A: 运行 `pip install pandas openpyxl`

**Q: CSV 文件在 Excel 中打开乱码？**
A: 使用 UTF-8-BOM 编码保存，应该不会乱码。如果还有问题，用 Excel 的"数据"-"从文本导入"功能。

**Q: 如何查看 SQLite 数据？**sqlite_datas/notes.db`

**Q: 能同时使用多种格式吗？**
A: 当前版本每次运行只能选择一种格式，如需多种格式，请多次运行。

**Q: 不同格式的数据存在哪里？**
A: 根据格式自动存储到专用文件夹：`sqlite_datas/`、`csv_datas/`、`json_datas/`、`excel_datas/`
A: 当前版本每次运行只能选择一种格式，如需多种格式，请多次运行。
